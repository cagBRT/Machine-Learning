{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO50FWQslCS/pOHddw0M84Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/Multi_Output_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QL4TvuDaO9Ob"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qNx3feMX4UQ"
      },
      "outputs": [],
      "source": [
        "# check scikit-learn version\n",
        "import sklearn\n",
        "print(sklearn.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Input: 10 numeric variables.\n",
        "Problem Output: 2 numeric variables."
      ],
      "metadata": {
        "id": "TmtbNvmpX95X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of multioutput regression test problem\n",
        "from sklearn.datasets import make_regression\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# summarize dataset\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "TcD_qSnPX-l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linear regression for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = LinearRegression()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "id": "yG2WMhs9YD1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# k-nearest neighbors for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = KNeighborsRegressor()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "id": "Y4u1SjoYYHVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree for multioutput regression\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = DecisionTreeRegressor()\n",
        "# fit model\n",
        "model.fit(X, y)\n",
        "# make a prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = model.predict([row])\n",
        "# summarize prediction\n",
        "print(yhat[0])"
      ],
      "metadata": {
        "id": "fAIGXA89YK4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate multioutput regression model with k-fold cross-validation\n",
        "from numpy import absolute\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define model\n",
        "model = DecisionTreeRegressor()\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "sgvbUSSnYPP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# failure of support vector regression for multioutput regression (causes an error)\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.svm import LinearSVR\n",
        "# create datasets\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1)\n",
        "# define model\n",
        "model = LinearSVR()\n",
        "# fit model\n",
        "# (THIS WILL CAUSE AN ERROR!)\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "bD5pdn_cYd4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A workaround for using regression models designed for predicting one value for multioutput regression is to divide the multioutput regression problem into multiple sub-problems.\n",
        "\n",
        "The most obvious way to do this is to split a multioutput regression problem into multiple single-output regression problems.\n",
        "\n",
        "For example, if a multioutput regression problem required the prediction of three values y1, y2 and y3 given an input X, then this could be partitioned into three single-output regression problems:\n",
        "\n",
        "Problem 1: Given X, predict y1.\n",
        "Problem 2: Given X, predict y2.\n",
        "Problem 3: Given X, predict y3.\n",
        "There are two main approaches to implementing this technique.\n",
        "\n",
        "The first approach involves developing a separate regression model for each output value to be predicted. We can think of this as a direct approach, as each target value is modeled directly.\n",
        "\n",
        "The second approach is an extension of the first method except the models are organized into a chain. The prediction from the first model is taken as part of the input to the second model, and the process of output-to-input dependency repeats along the chain of models.\n",
        "\n",
        "Direct Multioutput: Develop an independent model for each numerical value to be predicted.\n",
        "Chained Multioutput: Develop a sequence of dependent models to match the number of numerical values to be predicted.\n",
        "Letâ€™s take a closer look at each of these techniques in turn."
      ],
      "metadata": {
        "id": "a4pDAR3wZCGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# example of evaluating direct multioutput regression with an SVM model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import absolute\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import LinearSVR"
      ],
      "metadata": {
        "id": "TrNrDy7BZkR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the direct multioutput wrapper model\n",
        "wrapper = MultiOutputRegressor(model)\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# evaluate the model and collect the scores\n",
        "n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
        "# force the scores to be positive\n",
        "n_scores = absolute(n_scores)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "metadata": {
        "id": "IpgB9iFIZCt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of making a prediction with the direct multioutput regression model\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.svm import LinearSVR\n",
        "# define dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=2, random_state=1, noise=0.5)\n",
        "# define base model\n",
        "model = LinearSVR()\n",
        "# define the direct multioutput wrapper model\n",
        "wrapper = MultiOutputRegressor(model)\n",
        "# fit the model on the whole dataset\n",
        "wrapper.fit(X, y)\n",
        "# make a single prediction\n",
        "row = [0.21947749, 0.32948997, 0.81560036, 0.440956, -0.0606303, -0.29257894, -0.2820059, -0.00290545, 0.96402263, 0.04992249]\n",
        "yhat = wrapper.predict([row])\n",
        "# summarize the prediction\n",
        "print('Predicted: %s' % yhat[0])"
      ],
      "metadata": {
        "id": "kQGWtDJHZvV-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}