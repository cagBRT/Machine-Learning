{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM MultiClass.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNC1KubBbWvEWDKJdsV4Vkb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/SVM_MultiClass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tvs43GpUPg3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcIl0DlzMtPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PyLab is a procedural interface to the Matplotlib object-oriented plotting library.\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix,classification_report\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DCBFkLTS2D9",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset<br>\n",
        "\n",
        "The Human Activity Recognition database was built from the recordings of 30 study participants performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. <br><br>\n",
        "The objective is to classify activities into one of the six activities performed.<br>\n",
        "<br>\n",
        "https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y_3l9BUQBxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = shuffle(pd.read_csv(\"trainPhone.csv\"))\n",
        "test = shuffle(pd.read_csv(\"testPhone.csv\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD048JTfUNIw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train.shape)\n",
        "print(train.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9Bb_O3TUGz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY9gdtnSS4ce",
        "colab_type": "text"
      },
      "source": [
        "Check for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJVmnxrrQLK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Any missing sample in training set:\",train.isnull().values.any())\n",
        "print(\"Any missing sample in test set:\",test.isnull().values.any(), \"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCyaXTr9S8Vg",
        "colab_type": "text"
      },
      "source": [
        "Check the distribution of the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_nt-jElQN4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Frequency distribution of classes\"\n",
        "train_outcome = pd.crosstab(index=train[\"Activity\"],  # Make a crosstab\n",
        "                              columns=\"count\")      # Name the count column\n",
        "\n",
        "train_outcome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmfLHQnAQS_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizing Outcome Distribution \n",
        "temp = train[\"Activity\"].value_counts()\n",
        "df = pd.DataFrame({'labels': temp.index,\n",
        "                   'values': temp.values\n",
        "                  })\n",
        "\n",
        "#df.plot(kind='pie',labels='labels',values='values', title='Activity Ditribution',subplots= \"True\")\n",
        "\n",
        "labels = df['labels']\n",
        "sizes = df['values']\n",
        "colors = ['yellowgreen', 'gold', 'lightskyblue', 'lightcoral','cyan','lightpink']\n",
        "patches, texts = plt.pie(sizes, colors=colors, shadow=True, startangle=90, pctdistance=1.1, labeldistance=1.2)\n",
        "plt.legend(patches, labels, loc=\"best\")\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkbabEoJTjo4",
        "colab_type": "text"
      },
      "source": [
        "Separate the the labels from the features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vay0PMVZTtAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seperating Predictors and Outcome values from train and test sets\n",
        "X_train = pd.DataFrame(train.drop(['Activity','subject'],axis=1))\n",
        "Y_train_label = train.Activity.values.astype(object)\n",
        "X_test = pd.DataFrame(test.drop(['Activity','subject'],axis=1))\n",
        "Y_test_label = test.Activity.values.astype(object)\n",
        "\n",
        "# Dimension of Train and Test set \n",
        "print(\"Dimension of Train set\",X_train.shape)\n",
        "print(\"Dimension of Test set\",X_test.shape,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEyJFV0HTyxg",
        "colab_type": "text"
      },
      "source": [
        "Transform the labels into numerical categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRZb0SEgT7Kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transforming non numerical labels into numerical labels\n",
        "\n",
        "encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# encoding train labels \n",
        "encoder.fit(Y_train_label)\n",
        "Y_train = encoder.transform(Y_train_label)\n",
        "\n",
        "# encoding test labels \n",
        "encoder.fit(Y_test_label)\n",
        "Y_test = encoder.transform(Y_test_label)\n",
        "\n",
        "#Total Number of Continous and Categorical features in the training set\n",
        "num_cols = X_train._get_numeric_data().columns\n",
        "print(\"Number of numeric features:\",num_cols.size)\n",
        "#list(set(X_train.columns) - set(num_cols))\n",
        "names_of_predictors = list(X_train.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ3tABsLUpbZ",
        "colab_type": "text"
      },
      "source": [
        "Standardize features by removing the mean and scaling to unit variance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJsi6yurQWxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scaling the Train and Test feature set \n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGWEgo2HU-2r",
        "colab_type": "text"
      },
      "source": [
        "HyperParameter tuning using grid search and cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12JWPp5pQZw5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Libraries to Build Ensemble Model : Random Forest Classifier \n",
        "# Create the parameter grid based on the results of random search \n",
        "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q-MtsCgZMVS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the best parameters for the model found using grid search\n",
        "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
        "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
        "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btda8R-pVFbT",
        "colab_type": "text"
      },
      "source": [
        "Train the model<br>\n",
        "This will take ~5 minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5NArz9jQeO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Performing CV to tune parameters for best SVM fit \n",
        "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
        "svm_model.fit(X_train_scaled, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUMTrzTtVMed",
        "colab_type": "text"
      },
      "source": [
        "Determine the Accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzxWbE9WQi_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# View the accuracy score\n",
        "print('Best score for training data:', svm_model.best_score_,\"\\n\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jtjh1N6Vbii",
        "colab_type": "text"
      },
      "source": [
        "Make predictions with the best estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1oZ37p-VV36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_model = svm_model.best_estimator_\n",
        "Y_pred = final_model.predict(X_test_scaled)\n",
        "Y_pred_label = list(encoder.inverse_transform(Y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AdAU05mQmFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making the Confusion Matrix\n",
        "#print(pd.crosstab(Y_test_label, Y_pred_label, rownames=['Actual Activity'], colnames=['Predicted Activity']))\n",
        "print(confusion_matrix(Y_test_label,Y_pred_label))\n",
        "print(\"\\n\")\n",
        "print(classification_report(Y_test_label,Y_pred_label))\n",
        "\n",
        "print(\"Training set score for SVM: %f\" % final_model.score(X_train_scaled , Y_train))\n",
        "print(\"Testing  set score for SVM: %f\" % final_model.score(X_test_scaled  , Y_test ))\n",
        "\n",
        "svm_model.score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}