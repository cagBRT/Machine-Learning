{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA3.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNOwBeg6iwLuIYM5oKAZH66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/PCA3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avbXuWWJ53-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1--exM11F_3",
        "colab_type": "text"
      },
      "source": [
        "The usefulness of the dimensionality reduction may not be entirely apparent in only two dimensions, but becomes much more clear when looking at high-dimensional data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuszzvpwNw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj-v9p0V1M0q",
        "colab_type": "text"
      },
      "source": [
        "Load the data: hand drawn digits<br>\n",
        "\n",
        "The data consists of 8√ó8 pixel images, meaning that they are 64-dimensional (or features)\n",
        "To gain some intuition into the relationships between these points, we can use PCA to project them to a more manageable number of dimensions, say two:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGy5x_K6vymV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = load_digits()\n",
        "digits.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgAWXyTev2kM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(2)  # project from 64 to 2 dimensions\n",
        "projected = pca.fit_transform(digits.data)\n",
        "print(digits.data.shape)\n",
        "print(projected.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C09SAUZ4FFV",
        "colab_type": "text"
      },
      "source": [
        "We can now plot the first two principal components of each point to learn about the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed_Hra3DwHMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.scatter(projected[:, 0], projected[:, 1],\n",
        "            c=digits.target, edgecolor='none', alpha=0.5,\n",
        "            cmap=plt.cm.get_cmap('Spectral', 10))\n",
        "\n",
        "plt.xlabel('component 1')\n",
        "plt.ylabel('component 2')\n",
        "plt.colorbar();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBTF_wdQ42oy",
        "colab_type": "text"
      },
      "source": [
        "Each image in the training set is defined by a collection of 64 pixel values, which we will call the vector  ùë• :\n",
        "\n",
        "ùë•=[ùë•1,ùë•2,ùë•3‚ãØùë•64] \n",
        "\n",
        "One way we can think about this is in terms of a pixel basis. That is, to construct the image, we multiply each element of the vector by the pixel it describes, and then add the results together to build the image:\n",
        "\n",
        "image(ùë•)=ùë•1‚ãÖ(pixel 1)+ùë•2‚ãÖ(pixel 2)+ùë•3‚ãÖ(pixel 3)‚ãØùë•64‚ãÖ(pixel 64)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw3cz9x76PT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"pixels.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Os5UHHTy6r9V",
        "colab_type": "text"
      },
      "source": [
        "But the pixel-wise representation is not the only choice of basis. We can also use other basis functions, which each contain some pre-defined contribution from each pixel, and write something like\n",
        "\n",
        "$$\n",
        "image(x) = {\\rm mean} + x_1 \\cdot{\\rm (basis~1)} + x_2 \\cdot{\\rm (basis~2)} + x_3 \\cdot{\\rm (basis~3)} \\cdots\n",
        "$$\n",
        "\n",
        "PCA can be thought of as a process of choosing optimal basis functions, such that adding together just the first few of them is enough to suitably reconstruct the bulk of the elements in the dataset.\n",
        "The principal components, which act as the low-dimensional representation of our data, are simply the coefficients that multiply each of the elements in this series.\n",
        "This figure shows a similar depiction of reconstructing this digit using the mean plus the first eight PCA basis functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihFk2v0r68Xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Image(\"pca.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g35H_83VymvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA().fit(digits.data)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}