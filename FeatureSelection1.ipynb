{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/FeatureSelection1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZbvUJozkSK9"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V45LbE9PTFN8"
      },
      "source": [
        "from IPython.display import Image\n",
        "def page(num):\n",
        "    return Image(\"images/fs\"+str(num)+ \".png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63bcOe2GTPUM"
      },
      "source": [
        "page(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mrTjYsgT0sy"
      },
      "source": [
        "page(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pz6sNNYPT30z"
      },
      "source": [
        "page(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waDSPuyET5tg"
      },
      "source": [
        "page(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQEBLV1gT7pQ"
      },
      "source": [
        "page(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLK5S7z8T9aS"
      },
      "source": [
        "page(6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOtFp5onT_ja"
      },
      "source": [
        "page(7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COGWKfVFUB1e"
      },
      "source": [
        "page(8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuAxoMjiUDuc"
      },
      "source": [
        "page(9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOcesl303r56"
      },
      "source": [
        "# **Remove features with low variance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDFQycru2-qn"
      },
      "source": [
        "As an example, suppose that we have a dataset with boolean features, and we want to remove all features that are either one or zero (on or off) in more than 80% of the samples. Any data where 80% of the data is the same is considered low variance data. <br>\n",
        "\n",
        "Features with a training-set variance lower than this threshold will be removed. <br>\n",
        "**The default is to keep all features with non-zero variance**, i.e. remove the features that have the same value in all samples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POAg-2gY24St"
      },
      "source": [
        "Create a datasest with 3 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcYMkGMb2skT"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "X = [[0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1]]\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnwIBmvd28Os"
      },
      "source": [
        "Remove all variables where the variance does not meet the threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCO728Dl3Tg0"
      },
      "source": [
        "As expected, VarianceThreshold has removed the first column, \n",
        "which had 0,0,1,0,0,0 <br>\n",
        "There is very little variance in this column, so it will not add much information for our model to use when making predictions. So remove this column.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fva4hqMO23Zc"
      },
      "source": [
        "sel = VarianceThreshold(threshold=(0.16))\n",
        "sel.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBCOIVj9-rIT"
      },
      "source": [
        "# **Assignment 1**\n",
        "Remove any low variance data from the given dataset.<br>\n",
        "<br>\n",
        "[[0,1,2,0,2],[2,2,1,0,1],[1,1,1,0,1],[0,2,1,0,0],[2,1,1,0,0],[1,1,2,0,0],[2,2,0,0,1],[1,0,1,0,1],[0,2,1,0,1],[2,1,1,1,0],[0,1,1,0,2],[1,2,0,0,1],[2,1,1,2,1],[2,0,1,0,1]]\n",
        "\n",
        "1. Find the lowest threshold that still produces a change in the dataset\n",
        "2. Find the threshold to remove a second feature column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwLCxkxzxDMU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G8M4kxJ-3X2",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#Assignment 1\n",
        "xx = [[0,1,2,0,2],[2,2,1,0,1],[1,1,1,0,1],[0,2,1,0,0],[2,1,1,0,0],[1,1,2,0,0],[2,2,0,0,1],[1,0,1,0,1],[0,2,1,0,1],[2,1,1,1,0],[0,1,1,0,2],[1,2,0,0,1],[2,1,1,0,1],[2,0,1,0,1]]\n",
        "sel = VarianceThreshold(threshold=(0.29))\n",
        "sel.fit_transform(xx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJIHYCf33xcY"
      },
      "source": [
        "# **Univariate feature selection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8JrQGnX_gPd"
      },
      "source": [
        ">SelectKBest removes all but the k highest scoring features<br>\n",
        "<br>\n",
        "SelectPercentile removes all but a user-specified highest scoring percentage of features<br>\n",
        "<br>\n",
        "Uses common univariate statistical tests for each feature:<br> \n",
        "* false positive rate SelectFpr<br>\n",
        "* false discovery rate SelectFdr<br>\n",
        "* family wise error SelectFwe<br>\n",
        "* genericUnivariateSelect - selects the best strategy with a hyper parameter search estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1ic1M-2Vx-K"
      },
      "source": [
        "page(13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8B00pdK73A9"
      },
      "source": [
        "**Example 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_5KUtl4JAQ"
      },
      "source": [
        "SelectKBest removes all but the *k* highest scoring features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwgyLw104RmF"
      },
      "source": [
        "Get the Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apd5gGI038ut"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFoLUqYr4UM0"
      },
      "source": [
        "These functions take as input a scoring function that returns univariate scores and p-values (or only scores for SelectKBest and SelectPercentile)<br>\n",
        "For regression use: f_regression, mutual_info_regression\n",
        "\n",
        "For classification use: chi2, f_classif, mutual_info_classif\n",
        "<br><br>\n",
        "Then select the highest scoring features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqmfKV64QI7"
      },
      "source": [
        "#Use chi2 to score the columns. Select the two columns that have the highest scores\n",
        "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
        "X_new.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rZc7Saf42Xk"
      },
      "source": [
        "**Example 2: Check model performance after variable selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgWBWHot5Ggn"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest, f_classif"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldQX2LpN5S35"
      },
      "source": [
        "**Get data and add noise to the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVBraRJ6pb6"
      },
      "source": [
        "As an experiment, use the Iris dataset, but add noise to it so that it has 24 features. <br>\n",
        "This data sets consists of 3 different types of irises’ (Setosa, Versicolour, and Virginica) petal and sepal length, stored in a 150x4 numpy.ndarray<br>\n",
        "\n",
        "The rows being the samples and the columns being: <br>\n",
        ">Sepal Length <br>\n",
        "Sepal Width <br>\n",
        "Petal Length <br>\n",
        "Petal Width<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx09fNN-bTDW"
      },
      "source": [
        "# Import the Iris dataset\n",
        "Xin, y = load_iris(return_X_y=True)\n",
        "iris = pd.DataFrame(Xin,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a13XPihgRd1c"
      },
      "source": [
        "Notice the column names are 0,1,2,3<br>\n",
        "The classes are the index. So to figure out the class of a row, look at the index. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67pI-sG9QKmb"
      },
      "source": [
        "iris"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbV__f91Rznp"
      },
      "source": [
        "Using the Pandas plot command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s7vU-RGPuUY"
      },
      "source": [
        "ax1 = iris.plot.scatter(x=0, y=2, c=y_index, colormap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMzdqQhNR7aj"
      },
      "source": [
        "ax2 = iris.plot.scatter(x=1, y=3, c=y_index, colormap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79mQ2T0v5Le-"
      },
      "source": [
        "# Some noisy data not correlated\n",
        "E = np.random.RandomState(42).uniform(0, 0.1, size=(X.shape[0], 20))\n",
        "\n",
        "# Add the noisy data to the informative features\n",
        "X = np.hstack((X, E))\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tsw8w6bpTMHe"
      },
      "source": [
        "#data row 0 with 20 columns of noise\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBnIyEZS5ciu"
      },
      "source": [
        "**Do the train-test split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e__nGiTs5ctJ"
      },
      "source": [
        "# Split dataset to select feature and evaluate the classifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, stratify=y, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unYrXy1w8vl0"
      },
      "source": [
        "**Create an SVM model and train it on all the features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUqPYLrY8beH"
      },
      "source": [
        "# Compare to the weights of an SVM\n",
        "clf = make_pipeline(MinMaxScaler(), LinearSVC())\n",
        "clf.fit(X_train, y_train)\n",
        "print('Classification accuracy without selecting features: {:.3f}'\n",
        "      .format(clf.score(X_test, y_test)))\n",
        "\n",
        "svm_weights = np.abs(clf[-1].coef_).sum(axis=0)\n",
        "svm_weights /= svm_weights.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBc_vio813K"
      },
      "source": [
        "**Create an SVM and train it with only the selected features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FP8xze960k3"
      },
      "source": [
        "# #############################################################################\n",
        "# Using the SelectKBest function, select the best 4 best features to keep\n",
        "# #############################################################################\n",
        "\n",
        "selector = SelectKBest(f_classif, k=2)\n",
        "selector.fit(X_train, y_train)\n",
        "scores = -np.log10(selector.pvalues_)\n",
        "scores /= scores.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1v6GqYa8raL"
      },
      "source": [
        "clf_selected = make_pipeline(\n",
        "        SelectKBest(f_classif, k=2), MinMaxScaler(), LinearSVC()\n",
        ")\n",
        "clf_selected.fit(X_train, y_train)\n",
        "print('Classification accuracy after univariate feature selection: {:.3f}'\n",
        "      .format(clf_selected.score(X_test, y_test)))\n",
        "\n",
        "svm_weights_selected = np.abs(clf_selected[-1].coef_).sum(axis=0)\n",
        "svm_weights_selected /= svm_weights_selected.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkoG3hmOsyJ6"
      },
      "source": [
        "It is clear the model that used only the highest scoring SelectKBest values has a higher performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKAGpuqY42j0"
      },
      "source": [
        "X_indices = np.arange(X.shape[-1])\n",
        "plt.figure(1)\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.clf()\n",
        "\n",
        "plt.bar(X_indices - .45, scores, width=.2,\n",
        "        label=r'Univariate score ($-Log(p_{value})$)')\n",
        "\n",
        "plt.bar(X_indices - .25, svm_weights, width=.2, label='SVM weight')\n",
        "\n",
        "plt.bar(X_indices[selector.get_support()] - .05, svm_weights_selected,\n",
        "        width=.2, label='SVM weights after selection')\n",
        "\n",
        "plt.title(\"Comparing feature selection\")\n",
        "plt.xlabel('Feature number')\n",
        "plt.yticks(())\n",
        "plt.axis('tight')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFltpomvtCOE"
      },
      "source": [
        "# **Assignment 2**\n",
        "The plot above shows two of the univariate scores are much higher that the other scores. <br>\n",
        "Train the model using only the two highest scores. <br>\n",
        "Does the model performance get better or worse?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVWoHICAtVTw"
      },
      "source": [
        "#Assignment 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5_JuVR5A5AS"
      },
      "source": [
        "# **Recursive feature elimination**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8jbPnvrXFI7"
      },
      "source": [
        "page(14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h40xDwCHEFes"
      },
      "source": [
        "A recursive feature elimination example showing the relevance of pixels in a digit classification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_EeaIamB7f9"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.feature_selection import RFE\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH9bq_cBCVs5"
      },
      "source": [
        "**Load the digits dataset (classification)**.<br>\n",
        "\n",
        "Each datapoint is a 8x8 image of a digit.<br>\n",
        ">Classes: 10<br>\n",
        ">Samples per class: ~180<br>\n",
        ">Samples total: 1797<br>\n",
        ">Dimensionality: 64<br>\n",
        ">Features: integers 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-ZCYFMB_vh"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "print(digits.data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9YqCTcbNUk3"
      },
      "source": [
        "X = digits.images.reshape((len(digits.images), -1))\n",
        "y = digits.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INisXSxvNkxd"
      },
      "source": [
        "Look at one of the digits, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x73tlGFjCzlk"
      },
      "source": [
        "choice = 567 #(0-1796)\n",
        "plt.gray() \n",
        "plt.matshow(digits.images[choice]) \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mTlUFUWw7X5"
      },
      "source": [
        "There are 64 pixels in the image. <br>\n",
        "Which ones are important to the model and which ones can we prune?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtqs9FgQCLOq"
      },
      "source": [
        "X[choice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xisTpJlaCJPr"
      },
      "source": [
        "y[choice]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xki-A_fINo0l"
      },
      "source": [
        "Create the Recursive Feature Elimination (RFE) object and rank each pixel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jb8botiCGcJ"
      },
      "source": [
        "svc = SVC(kernel=\"linear\", C=1) \n",
        "rfe = RFE(estimator=svc, n_features_to_select=1, step=1)\n",
        "rfe.fit(X, y)\n",
        "ranking = rfe.ranking_.reshape(digits.images[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YefxVKatxN4B"
      },
      "source": [
        "List the ranks assigned to each pixel. <br>\n",
        "The higher the ranking corresponds to which should be pruned first. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekgTugnexKmH"
      },
      "source": [
        "ranking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVWtP_RxNvaM"
      },
      "source": [
        "Plot pixel ranking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0lukojWA-pG"
      },
      "source": [
        "plt.matshow(ranking, cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "plt.title(\"Ranking of pixels with RFE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bdfums7Nb7SK"
      },
      "source": [
        "# **Assignment 3**\n",
        "Right now the model is saving only one pixel. Change the number of pixels saved to 48 pixels. <br>\n",
        "Rerun the ranking of the pixels. <br>\n",
        "Then run the code below.<br>\n",
        "Which pixels were removed? <br>\n",
        "After removing the pixels compare the performance of the reduced pixel images to the performance of the full image. <br>\n",
        "How much of a difference is there in the accuracy scores?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uLpk20ruMWt"
      },
      "source": [
        "The model with all but one feature removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqr9QW4eXzxR"
      },
      "source": [
        "svc = SVC(kernel=\"linear\", C=1)\n",
        "rfe = RFE(estimator=svc, n_features_to_select=30, step=1) #Select 30 features\n",
        "rfe.fit(X, y)\n",
        "ranking = rfe.ranking_.reshape(digits.images[0].shape)\n",
        "print(ranking)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bygXkKkEzqxl"
      },
      "source": [
        "model = DecisionTreeClassifier()\n",
        "#List of (name, transform) tuples (implementing fit/transform) that are chained, \n",
        "#in the order in which they are chained, with the last object an estimator.\n",
        "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
        "pipeline.fit(X, y)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7ZuHWrWuSVF"
      },
      "source": [
        "The model with all features used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqHu1xQRaW2V"
      },
      "source": [
        "model.fit(X, y)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Zlr1NriEZlV"
      },
      "source": [
        "**RFE Example  2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOHbdbSFEpNB"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.datasets import make_classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NQRbGkEEw_X"
      },
      "source": [
        "**Create the data with 3 informative features and 25 features total**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCq1iS_cE4IE"
      },
      "source": [
        "# Build a classification task using 3 informative features\n",
        "X2, y2 = make_classification(n_samples=1000, n_features=25, n_informative=10,\n",
        "                           n_redundant=2, n_repeated=0, n_classes=8,\n",
        "                           n_clusters_per_class=1, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUXLTTroE-0i"
      },
      "source": [
        "**Create the RFE object**<br>\n",
        "Using a cross-validated score, recursively eliminate the less important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLZkiT8FE9YO"
      },
      "source": [
        "# Create the RFE object and compute a cross-validated score.\n",
        "svc = SVC(kernel=\"linear\")\n",
        "# The \"accuracy\" scoring is proportional to the number of correct\n",
        "# classifications\n",
        "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2),\n",
        "              scoring='accuracy')\n",
        "rfecv.fit(X2, y2)\n",
        "\n",
        "print(\"Optimal number of features : %d\" % rfecv.n_features_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S8oCqCRFUr5"
      },
      "source": [
        "**Plot the score vs number of features selected**<br>\n",
        "The validation score drops as the number of non-informative features increases. <br>\n",
        "We know that the data we created has 3 informative features and 25 features total, so this agrees with what we expect. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxiZTZoyEdaz"
      },
      "source": [
        "# Plot number of features VS. cross-validation scores\n",
        "plt.figure()\n",
        "plt.xlabel(\"Number of features selected\")\n",
        "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
        "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESapQMWBdfc9"
      },
      "source": [
        "# **Assignment 4**\n",
        "The following example uses a dataset from a Kaggle competition. <br>\n",
        "The training set has 250 rows and 302 columns of data. <br>\n",
        "The example will use RFE to determine which columns (or features) are actually informative. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCGD8ITK3xo9"
      },
      "source": [
        "Your assignment, determine how many features should be kept of the 302 available?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vyezXnllq-S"
      },
      "source": [
        "# setting up default plotting parameters\n",
        "%matplotlib inline\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
        "plt.rcParams.update({'font.size': 22,})\n",
        "\n",
        "sns.set_palette('viridis')\n",
        "sns.set_style('white')\n",
        "sns.set_context('talk', font_scale=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYukq3UKluyJ"
      },
      "source": [
        "train = pd.read_csv('featureSelectTrain.csv')\n",
        "test = pd.read_csv('featureSelectTest.csv')\n",
        "\n",
        "print('Train Shape: ', train.shape)\n",
        "print('Test Shape: ', test.shape)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt_z1IYqqhKN"
      },
      "source": [
        "# prepare for modeling\n",
        "X_train_df = train.drop(['id', 'target'], axis=1)\n",
        "y_train = train['target']\n",
        "\n",
        "X_test = test.drop(['id'], axis=1)\n",
        "\n",
        "# scaling data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train_df)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onOcYoSe017l"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaEOluaM06CC"
      },
      "source": [
        "Using the built-in method cumsum, there are 67 rows with the label '1' and 183 with the label '0'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BJTnAhZ0msY"
      },
      "source": [
        "y_train.cumsum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cgum9Mwe8P"
      },
      "source": [
        "Since there are two classes, use logistic regression (classification with two classes) for this dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sreLOKaYqJ2y"
      },
      "source": [
        "lr = LogisticRegression(solver='liblinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO8nrd-5wrQy"
      },
      "source": [
        "Use feature extraction to select the 100 most informative features. <br>\n",
        "Then train the model on these features and get the accuracy scores. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se6ndwRi4NnL"
      },
      "source": [
        "The model with all features selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQkIM5exrmzO"
      },
      "source": [
        "modelLR = lr.fit(X_train, y_train)\n",
        "modelLR_scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='roc_auc')\n",
        "print('Model Scores: ', modelLR_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b86ST3JN4ATC"
      },
      "source": [
        "**Change the n_features_to_select value to find the optimum number of features to select**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csGG1xzTpmfz"
      },
      "source": [
        "# feature extraction\n",
        "#Change the n_features_to_select\n",
        "rfe = RFE(lr, n_features_to_select=#) #put in number here\n",
        "\n",
        "# fit on train set\n",
        "fit = rfe.fit(X_train, y_train)\n",
        "\n",
        "# transformed train set\n",
        "recursive_features = fit.transform(X_train)\n",
        "\n",
        "lr_scores = cross_val_score(lr, recursive_features, y_train, cv=5, scoring='roc_auc')\n",
        "print('LR Scores: ', lr_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ugzVv31OTs"
      },
      "source": [
        "recursive_features.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luqL4CfthrZy"
      },
      "source": [
        "selected_featuresModel = lr.fit(recursive_features, y_train)\n",
        "#selected_featuresModel.coef_[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtUKTJ4prUzs"
      },
      "source": [
        "# checking which are the most important features\n",
        "feature_importance = selected_featuresModel.coef_[0]\n",
        "# Make importances relative to max importance.\n",
        "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
        "sorted_idx = np.argsort(feature_importance)\n",
        "sorted_idx = sorted_idx[-20:-1:1]\n",
        "pos = np.arange(sorted_idx.shape[0]) + .5\n",
        "pos.dtype.names\n",
        "X_train_df.columns[sorted_idx]\n",
        "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
        "plt.yticks(pos, X_train_df.columns[sorted_idx])\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.title('Feature Importance', fontsize=30)\n",
        "plt.tick_params(axis='x', which='major', labelsize=15)\n",
        "sns.despine(left=True, bottom=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b59LdV1cG5gV"
      },
      "source": [
        "# **SelectFromModel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UI7BX7uJBlFx"
      },
      "source": [
        "To use the SelectFromModel feature extraction, you can specify a threshold value. <br>\n",
        "\n",
        "There are also built-in heuristics for finding a threshold using a string argument. Available heuristics are “mean”, “median” and float multiples of these like “0.1*mean”. <br>\n",
        "\n",
        "In combination with the threshold criteria, one can use the max_features parameter to set a limit on the number of features to select."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWg3BQHsigBb"
      },
      "source": [
        "The features that are considered unimportant and removed. <br>\n",
        "Meaning if the corresponding coef_ or feature_importances_ values are below the provided threshold parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_ENV5cQKoon"
      },
      "source": [
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kXicbxPKttO"
      },
      "source": [
        "**Create data**<br>\n",
        "Four rows with four features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlZCfGnjG5tG"
      },
      "source": [
        "X3 = [[ 0.87, -1.34,  0.31, -0.99],\n",
        "     [-2.79, -0.02, -0.85, 0.5 ],\n",
        "     [-1.34, -0.48, -2.55, 2.01 ],\n",
        "     [ 1.92,  1.48,  0.65, 0.95 ]]\n",
        "y3 = [0, 1, 0, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQipiosTOMkb"
      },
      "source": [
        "Use SelectFromModel to determine which features are more important<br>\n",
        "True = important feature<br>\n",
        "False =  not important feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82Tpdh8ZKs2h"
      },
      "source": [
        "selector = SelectFromModel(estimator=LogisticRegression()).fit(X3, y3)\n",
        "print(\"selector estimator coef: \", selector.estimator_.coef_)\n",
        "print(\"selector threshold: \",selector.threshold_)\n",
        "print(\"selector get support: \",selector.get_support())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUGMAONJLJJN"
      },
      "source": [
        "selector.transform(X3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln4wzZEZB-6z"
      },
      "source": [
        "#**SelectFromModel using SVM** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE5XNjGDEhW8"
      },
      "source": [
        "**SelectFromModel Example 2** using linear support vector machine and the Iris dataset. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rCAQnKSDADq"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn import datasets\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCElJ5B4ZzIE"
      },
      "source": [
        "Look at the shape and feature names of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI5eD9hpTvJJ"
      },
      "source": [
        "X5 = iris.data[:,:]\n",
        "y5 =iris.target\n",
        "X5.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTykVyo2Q9yF"
      },
      "source": [
        "iris.feature_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t7ic3uhgPe4"
      },
      "source": [
        "Split the dataset into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybNkiUVHfFS7"
      },
      "source": [
        "X5_train, X5_test, y5_train, y5_test = train_test_split(\n",
        "    X5, y5, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQZgPQFXZ64x"
      },
      "source": [
        "Use a Linear Support vector model and select from the model the best features to keep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttje9iqvDG2t"
      },
      "source": [
        "#dual = True when the number of features > the number of rows\n",
        "#With SVMs and logistic-regression, the parameter C controls the sparsity:\n",
        "#the smaller C the fewer features selected.\n",
        "#Penalty specifies the norm used in the penalization.\n",
        "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False, max_iter=5000).fit(X5_train, y5_train)\n",
        "\n",
        "#REMOVE THE FEATURES THE ARE UNIMPORTANT\n",
        "model4 = SelectFromModel(lsvc, prefit=True)\n",
        "X5_new_train = model4.transform(X5_train)\n",
        "X5_new_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGd1prt2fiE-"
      },
      "source": [
        "X5_new_test = model4.transform(X5_test)\n",
        "X5_new_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgnM9fK9aEvu"
      },
      "source": [
        "See which features were kept"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCiCxIzbVSzw"
      },
      "source": [
        "feature_idx= model4.get_support()\n",
        "feature_idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEWeKSdugXAg"
      },
      "source": [
        "Train the model on the new feature set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iImVqgNUdJef"
      },
      "source": [
        "model5 = lsvc.fit(X5_new_train,y5_train)\n",
        "model5.score(X5_new_test,y5_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6gUEh_NgaRe"
      },
      "source": [
        "Train the model on the full feature set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1erz88EKdgjk"
      },
      "source": [
        "model5new = lsvc.fit(X5,y5)\n",
        "model5new.score(X5,y5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7vwWcp2geMf"
      },
      "source": [
        "# **Assignment 5**\n",
        "Change the ratio of the training and test sets. Run code cells in this example again.<br>\n",
        "Explain the differences between the two runs of the code. <br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhRPFr6spzhK"
      },
      "source": [
        "# **SelectFromModel**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oNA0eNYZV7z"
      },
      "source": [
        "# **Assignment 6**<br>\n",
        "The Diabetes dataset consists of 10 variables (features) collected from 442 diabetes patients. This example shows how to use SelectFromModel and LassoCv to find the best two features predicting disease progression after one year from the baseline.<br>\n",
        "\n",
        "When the model is trained on the two best features, the performance drops by ~20%.<br>\n",
        "Find the number of features that will keep the performance the same, but reduce the size of the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny2EFqQnaagG"
      },
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAHDGHBJ5C0U"
      },
      "source": [
        "Load the data and list the feature names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wzyXjtmazf1"
      },
      "source": [
        "diabetes = load_diabetes()\n",
        "X7 = diabetes.data\n",
        "y7 = diabetes.target\n",
        "\n",
        "feature_names = diabetes.feature_names\n",
        "print(feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHeOdkiwjO0X"
      },
      "source": [
        "Determine which features are important using the LassoCV algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tekDFPcDa7Sh"
      },
      "source": [
        "#LassoCV alogrithm is used with the full data\n",
        "clf = LassoCV().fit(X7, y7)\n",
        "importance = np.abs(clf.coef_)\n",
        "print(importance, \"\\n\")\n",
        "print(importance.argsort())\n",
        "#Argsort prints the index values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT5ZYH8SbCtI"
      },
      "source": [
        "idx_third = importance.argsort()[-3]\n",
        "print(idx_third)\n",
        "threshold = importance[idx_third] + 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8usoTdG_pmP"
      },
      "source": [
        "To see what features were selected, change the number of features shown.<br>\n",
        "[:2] will show two features<br>\n",
        "...<br>\n",
        "[:9] will show 8 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfeuu12QbXmS"
      },
      "source": [
        "idx_features = (-importance).argsort()[:10]\n",
        "name_features = np.array(feature_names)[idx_features]\n",
        "print('Selected features: {}'.format(name_features))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb2DuzVV__XK"
      },
      "source": [
        "The plot shows the importance of each feature. The higher the number the more important the feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYAJtpfulJ80"
      },
      "source": [
        "plt.bar(feature_names,importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1YgQXPCpa8i"
      },
      "source": [
        "#**Assignment 7**\n",
        "Change the threshold of the SelectFromModel alogrithm. <br>\n",
        "What effect does it have on the performance of the model? <br>\n",
        "What does it say about the model and/or the data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J0KTqMzm9ZD"
      },
      "source": [
        "Train a classification model on the full feature training data set and then on the select feature training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwp8poO0ra1c"
      },
      "source": [
        "#Use the threshold to selectFromModel\n",
        "sfm = SelectFromModel(clf, threshold=568)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXarpqEJoXOs"
      },
      "source": [
        "Below is printed the level of importance for each feature. \n",
        "Select a new threshold from these importance levels and see how the performance of the model changes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2-33o6Ln1oF"
      },
      "source": [
        "print(importance, \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieduhokWnWks"
      },
      "source": [
        "sfm.fit(X7, y7)\n",
        "X7_transform = sfm.transform(X7)\n",
        "X7_transform.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeWvwnd2AIwE"
      },
      "source": [
        "Train a linear regression model on all the features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLtTmVCc2et9"
      },
      "source": [
        "model9 = LinearRegression().fit(X7, y7)\n",
        "model9.score(X7, y7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO8x1RCDAO-H"
      },
      "source": [
        "Train a linear regression model on the selected features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxjaH3uFoEYV"
      },
      "source": [
        "model9_new = LinearRegression().fit(X7_transform, y7)\n",
        "model9_new.score(X7_transform, y7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-qsEES2LtAj"
      },
      "source": [
        "# **Tree-based feature selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVu78eMJMi5h"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Di_PyAWMk-w"
      },
      "source": [
        "Load the Iris datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDeNCmfrMoz1"
      },
      "source": [
        "X, y = load_iris(return_X_y=True)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_HYHguBPRjO"
      },
      "source": [
        "X[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAH4wz2KPfk8"
      },
      "source": [
        "Use the trees classifier to determine the important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRBuzgCKLxjd"
      },
      "source": [
        "clf = ExtraTreesClassifier(n_estimators=50)\n",
        "clf = clf.fit(X, y)\n",
        "clf.feature_importances_      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMU9_TolPpPC"
      },
      "source": [
        "Create a new dataset that uses only the most important features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqjI_rpMr7v"
      },
      "source": [
        "model = SelectFromModel(clf, prefit=True)\n",
        "X_new = model.transform(X)\n",
        "X_new.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxqPtKsbPUIU"
      },
      "source": [
        "X_new[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NpXom4wP5vM"
      },
      "source": [
        "Tree based example 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3__TOkj2QAp8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiPefc7oQCR5"
      },
      "source": [
        "Create synthetic data<br>\n",
        ">10 features, 3 of them informative\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W54-7BlsQJ0n"
      },
      "source": [
        "# Build a classification task using 3 informative features\n",
        "X, y = make_classification(n_samples=1000,\n",
        "                           n_features=10,\n",
        "                           n_informative=3,\n",
        "                           n_redundant=0,\n",
        "                           n_repeated=0,\n",
        "                           n_classes=2,\n",
        "                           random_state=0,\n",
        "                           shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc0iQoqGQPAe"
      },
      "source": [
        "**Build a forest** and compute the impurity-based feature importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2IfvxG6QNkj"
      },
      "source": [
        "forest = ExtraTreesClassifier(n_estimators=250,\n",
        "                              random_state=0)\n",
        "forest.fit(X, y)\n",
        "importances = forest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsP3CvUtQfCj"
      },
      "source": [
        "**Print the feature ranking**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doxKFoNmQbsL"
      },
      "source": [
        "print(\"Feature ranking:\")\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZkm-Zp-QrBs"
      },
      "source": [
        "**Plot the impurity-based feature importances of the forest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhHSDFh_P7Z1"
      },
      "source": [
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(X.shape[1]), importances[indices],\n",
        "        color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(X.shape[1]), indices)\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}