{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA4.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPQBWPpR3V+2sW4kZDxtsrg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/PCA4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQA-lzez7wUZ",
        "colab_type": "text"
      },
      "source": [
        "## PCA as Noise Filtering\n",
        "\n",
        "PCA can also be used as a filtering approach for noisy data.<br>\n",
        "The idea is this: any components with variance much larger than the effect of the noise should be relatively unaffected by the noise.\n",
        "So if you reconstruct the data using just the largest subset of principal components, you should be preferentially keeping the signal and throwing out the noise.<br>\n",
        "\n",
        "Let's see how this looks with the digits data.\n",
        "First we will plot several of the input noise-free data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avbXuWWJ53-a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "print(\"done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuszzvpwNw-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from numpy import mean\n",
        "from numpy import std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj-v9p0V1M0q",
        "colab_type": "text"
      },
      "source": [
        "Load the data: hand drawn digits<br>\n",
        "\n",
        "The data consists of 8×8 pixel images, meaning that they are 64-dimensional (or features)<br>\n",
        "\n",
        "We can use PCA to project them to a more manageable number of dimensions, say two:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGy5x_K6vymV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digits = load_digits()\n",
        "digits.data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6opOuCbBmju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = digits.images.reshape((len(digits.images), -1))\n",
        "y = digits.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiAjcDTxIWwr",
        "colab_type": "text"
      },
      "source": [
        "# **Plot the digits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t694oVr-IMCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_digits(data):\n",
        "    fig, axes = plt.subplots(4, 10, figsize=(10, 4),\n",
        "                             subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                             gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        ax.imshow(data[i].reshape(8, 8),\n",
        "                  cmap='binary', interpolation='nearest',\n",
        "                  clim=(0, 16))\n",
        "plot_digits(digits.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTuEUnWpcZBF",
        "colab_type": "text"
      },
      "source": [
        "**Create a model to classifiy the digits** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbugBOeRCxwo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_orig = DecisionTreeClassifier()\n",
        "model_orig.fit(X, y)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model_orig, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRha0DxqIeft",
        "colab_type": "text"
      },
      "source": [
        "# **Add some random noise to create a noisy dataset, and re-plot it:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FrhkUbHIki8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)\n",
        "noisy = np.random.normal(digits.data, 4)\n",
        "plot_digits(noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gy1HhyG2dqNm",
        "colab_type": "text"
      },
      "source": [
        "**Train the model on the noisy data**\n",
        "What happens to the accuracy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtJ7HM3TcnoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_noise = DecisionTreeClassifier()\n",
        "model_noise.fit(noisy, y)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model_noise, noisy, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1s8Zy1PIs7k",
        "colab_type": "text"
      },
      "source": [
        "It's clear the images are noisy, and contain spurious pixels.<br>\n",
        "Let's train a PCA on the noisy data, requesting that the projection preserve a percentage of the variance:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AEUmLROI3V1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assignment 1 - make changes here\n",
        "pca = PCA(0.20).fit(noisy)\n",
        "pca.n_components_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoWF18DXI9WP",
        "colab_type": "text"
      },
      "source": [
        "In this case 50% of the variance amounts to 12 principal components. Now we compute these components, and then use the inverse of the transform to reconstruct the filtered digits:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqFY-88nJEjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "components = pca.transform(noisy)\n",
        "filtered = pca.inverse_transform(components)\n",
        "plot_digits(filtered)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wViSWnscJQAZ",
        "colab_type": "text"
      },
      "source": [
        "This signal preserving/noise filtering property makes PCA a very useful feature selection routine—for example, rather than training a classifier on very high-dimensional data, you might instead train the classifier on the lower-dimensional representation, which will automatically serve to filter out random noise in the inputs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdkPsZEDfXov",
        "colab_type": "text"
      },
      "source": [
        "Train the model on the filtered data<br>\n",
        "Note the improved accuracy over the noisy data, but the accuracy is not as good as the clean data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "imv8USeOewjy",
        "colab": {}
      },
      "source": [
        "model_filtered = DecisionTreeClassifier()\n",
        "model_filtered.fit(filtered, y)\n",
        "# evaluate model\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "n_scores = cross_val_score(model_filtered, filtered,y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
        "# report performance\n",
        "print('Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xn8zNeohgJaL",
        "colab_type": "text"
      },
      "source": [
        "# **Assignment 1**<br>\n",
        "1. Change the threshold for the variance for the filtered model. <br>\n",
        "2. What is the optimum threshold for variance to improve the accuracy of the filtered model?\n",
        "What happens to the accuracy of the model when the number of principal components changes?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhy6r4r8f_O2",
        "colab_type": "text"
      },
      "source": [
        "# **Assignment 2**<br>\n",
        "Plot the PCA curve for the filtered data. \n",
        "What is the optimum number of principal components?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAeKxMlhf6Ds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA().fit(filtered)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}