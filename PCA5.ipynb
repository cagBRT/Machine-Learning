{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA5.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN0WsSYvRQuFZkW7qIVSHgi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/PCA5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9vRst1Dkifj",
        "colab_type": "text"
      },
      "source": [
        "# This notebook uses Randomized PCA<br>\n",
        "The major difference between RandomizedPCA and PCA is:<br>\n",
        ">PCA is trying hard to pick the \"best\" basis vectors by looking for directions in which the original data varies most. <br>\n",
        "\n",
        ">Random projection is picking the directions randomly!\n",
        "\n",
        "The point is that random projects may be 'worse' because they're blindly picked, but may not be much worse at all, and of course **picking them randomly is much faster than running PCA**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "PfvIvw8OwuG8",
        "colab_type": "text"
      },
      "source": [
        "## Eigenfaces\n",
        "\n",
        "This notebook uses the Labeled Faces in the Wild dataset made available through Scikit-Learn:<br>\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html\n",
        "\n",
        "Note the face have already been localized and scaled to a common size. This is an important preprocessing piece for faical recognition andis a process that can require a large collection of training data.<br>\n",
        "\n",
        "This notebook uses PCA “eigenfaces” as a pre-processing step for facial recognition. The reason we chose this is because PCA is a broadly-applicable technique, which can be useful for a wide array of data types. Research in the field of facial recognition in particular, however, has shown that other more specific feature extraction methods are can be much more effective."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g69hb7Cxjs0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.decomposition import PCA as RandomizedPCA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGtqp71vtxeH",
        "colab_type": "text"
      },
      "source": [
        "Get the faces that have at least 60 images in the dataset.<br>\n",
        ">There are 1348 images in the selected dataset<br>\n",
        "There are 8 faces in the selected dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eAxI2j5QwuG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The extracted dataset will only retain pictures of people that have at least\n",
        "#min_faces_per_person different pictures.\n",
        "faces = fetch_lfw_people(min_faces_per_person=60)\n",
        "print(faces.target_names)\n",
        "print(faces.images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iHTLKBot4WW",
        "colab_type": "text"
      },
      "source": [
        "Plot the some of the faces that have at least 60 images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucHN3IzmlZ_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the photos\n",
        "fig, ax = plt.subplots(1, 8, figsize=(15, 4),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(0,8):\n",
        "    ax[i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n",
        "    ax[i].set_xlabel(faces.target[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "yKyi4dgswuG-",
        "colab_type": "text"
      },
      "source": [
        "Since this is a large dataset, we will use ``RandomizedPCA``—it contains a randomized method to approximate the first $N$ principal components much more quickly than the standard ``PCA`` estimator, and thus is very useful for high-dimensional data (here, a dimensionality of nearly 3,000 ... 62*47=2914 pixels).\n",
        "We will take a look at the first 150 components:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtJ57Bcpz4PU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for the assignment change this number 1 - 2900\n",
        "n_pcs = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "jcJRPPKVwuG-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = RandomizedPCA(n_pcs)\n",
        "pca.fit(faces.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eCICJlILwuG_",
        "colab_type": "text"
      },
      "source": [
        "In this case, it can be interesting to visualize the images associated with the first several principal components (these components are technically known as \"eigenvectors,\"\n",
        "so these types of images are often called \"eigenfaces\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "rvCe-UjSwuHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(3, 8, figsize=(15, 6),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FMC7QsgewuHD",
        "colab_type": "text"
      },
      "source": [
        "The results are very interesting, and give us insight into how the images vary: for example, the first few eigenfaces (from the top left) seem to be associated with the angle of lighting on the face, and later principal vectors seem to be picking out certain features, such as eyes, noses, and lips.\n",
        "Let's take a look at the cumulative variance of these components to see how much of the data information the projection is preserving:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "FmhDTmCWwuHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('number of components')\n",
        "plt.ylabel('cumulative explained variance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "9U-7vauGwuHF",
        "colab_type": "text"
      },
      "source": [
        "We see that these 150 components account for just over 90% of the variance.\n",
        "That would lead us to believe that using these 150 components, we would recover most of the essential characteristics of the data.\n",
        "To make this more concrete, we can compare the input images with the images reconstructed from these 150 components:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDuVfHW8yIvl",
        "colab_type": "text"
      },
      "source": [
        "Suppose you had a data set with 100 rows and each row had 500 columns. If you constructed a PCA like PCA(n_components = 10) and then called fit you'd find that components_ has 10 rows, one for each of the components you requested, and 500 columns as that's the input dimension.\n",
        "\n",
        "Transform takes all 100 rows of your data to be projected into this 10-dimensional space so the output would have 100 rows (1 for each in the input) but only 10 columns thus reducing the dimension of your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tSMwqjs8wuHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute the components and projected faces\n",
        "pca = RandomizedPCA(n_pcs)\n",
        "pca.fit(faces.data)\n",
        "components = pca.transform(faces.data)\n",
        "#reconstruct the image from the components\n",
        "projected = pca.inverse_transform(components)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "tcbo7dKhwuHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the results\n",
        "fig, ax = plt.subplots(2, 8, figsize=(15, 4),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(8):\n",
        "    ax[0, i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n",
        "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n",
        "    ax[1,i].set_xlabel(faces.target[i])\n",
        "    \n",
        "ax[0, 0].set_ylabel('full-dim\\ninput')\n",
        "ax[1, 0].set_ylabel('150-dim\\nreconstruction');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqP9TZFyzSFj",
        "colab_type": "text"
      },
      "source": [
        "## Assignment\n",
        "Change the number of components used PCA. When does the reconstructed image become \"acceptable\" to you?"
      ]
    }
  ]
}