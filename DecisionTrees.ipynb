{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTrees.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNj2xC2KhixKWUAqmMDAxOM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/DecisionTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4coQdmHbq3T"
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ--zXXnbI4e"
      },
      "source": [
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psT1lRjDZ7ym"
      },
      "source": [
        "A decision tree has branches, nodes, leaves, etc. <br>\n",
        "\n",
        "A root node is an initial node representing the entire sample or population, and it can get further divided into other nodes or homogeneous sets. <br>\n",
        "\n",
        "A decision node consists of two or more nodes that represent separate values of the attribute tested.\n",
        "\n",
        "**A leaf/terminal node does not split into further nodes, and it represents a decision**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuSrPmohbvHu"
      },
      "source": [
        "Image(\"/content/cloned-repo/images/Decision Tree.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wSfleyXiADq"
      },
      "source": [
        "Image(\"images/Decision Tree 2.png\" , width=640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja2uBMSiVfD_"
      },
      "source": [
        "from sklearn import tree\n",
        "X = [[0,0,0], [1,1,1],[1,0,1],[0,1,1],[0,0,1],[0,1,0],[0,1,0]]\n",
        "Y = [0, 1, 0,1,0,1,1]\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gisQvhk2ciER"
      },
      "source": [
        "tree.plot_tree(clf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrE_jIcWVjmu"
      },
      "source": [
        "clf.predict([[1,0,0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Y3HeiJe_Ho"
      },
      "source": [
        "predict_prob is a function that predicts class probabilities of the input samples X.\n",
        "\n",
        "The predicted class probability is the fraction of samples of the same\n",
        "class in a leaf.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqDTckZcVpt1"
      },
      "source": [
        "clf.predict_proba([[1,0,0]])\n",
        "clf.predict_proba(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwIZP4wVfuwJ"
      },
      "source": [
        "**Advantages of Decision Tree Algorithm:**<br>\n",
        "\n",
        "- Understanding the results is easier than other models. You can have the technical team program your decision tree model, so it works faster, and you can apply it to new instances. Its calculations have inclusion tests according to an instance, which is a qualitative or a quantitative model.<br>\n",
        "\n",
        "- It is non-parametric. The independent variables present in our problem don’t have to follow any specific probability distributions due to this reason. You can have collinear variables. Whether they are discriminating or not, it doesn’t have an impact on your decision tree because it doesn’t have to choose those variables.<br>\n",
        "\n",
        "- They are capable of working with missing values. CHAID puts all the missing values in a category, which you can merge with another one or keep separate from others.<br>\n",
        "\n",
        "- Extreme individual values (such as outliers) don’t have much effect on the decision trees. You can isolate them in small nodes so that they don’t affect the entire classification.<br>\n",
        "\n",
        "- It gives you a great visual representation of a decision-making process. Every branch of a decision tree stands for the factors that can affect your decisions, and you get to see a bigger picture. You can use decision trees to improve communication in your team. <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_B0chNtf8WV"
      },
      "source": [
        "**Disadvantages of Decision Tree Algorithm**<br>\n",
        "- It doesn’t analyze all the independent variables simultaneously. Instead, it evaluates them sequentially. Due to this, the tree never revises the division of a node at any level, which can cause bias in the tree’s choices. <br>\n",
        "\n",
        "- Modifying even a single variable can affect the entire tree if it’s close to the top. There are ways to solve this problem. For example, you can construct the tree on multiple samples and aggregate them according to a mean (or vote); this is called resampling. However, it leads to another set of problems as it reduces the readability of the model by making it more complex. So, through resampling, you can get rid of the best qualities of decision trees. Why is it a problem? Suppose one variable has all the qualities of a particular group, but it also has the quality according to which the tree splits. In this case, the tree would put it in the wrong class just because it has that important quality. <br>\n",
        "\n",
        "- All the nodes of a specific level in a decision tree depend on the nodes in their previous levels. In other words, how you define the nodes on level ‘n +1’ depends entirely on your definition for the nodes on the level ‘n.’ If your definition at level ‘n’ is wrong, all the subsequent levels and the nodes present in those levels would also be wrong\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyWRtOuuZiqv"
      },
      "source": [
        "**Decision Tree Classifier on the Iris Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A5Dwz0kVvcx"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlIhbjKbWMX2"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqojyQzMVzUF"
      },
      "source": [
        "tree.plot_tree(clf) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvKR0rkSW78x"
      },
      "source": [
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"iris\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nGKG9uKW_aF"
      },
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                     feature_names=iris.feature_names,  \n",
        "                     class_names=iris.target_names,  \n",
        "                     filled=True, rounded=True,  \n",
        "                     special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9sYJ8eCjIfw"
      },
      "source": [
        "**Decision Tree Classifier on the Diabetes Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylAON1s9j2TR"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
        "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK1RRyr5jVjh"
      },
      "source": [
        "col_names = ['pregnancies', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
        "# load dataset\n",
        "diabetes= pd.read_csv(\"pima_indians_diabetes.csv\", header=None, names=col_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bu-bgSckE7a"
      },
      "source": [
        "diabetes.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChbTGrI-k4zd"
      },
      "source": [
        "diabetes = diabetes.drop([0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh2ce8LJkP4-"
      },
      "source": [
        "#split dataset in features and target variable\n",
        "feature_cols = ['pregnancies', 'insulin', 'bmi', 'age','glucose','bp','pedigree']\n",
        "X = diabetes[feature_cols] # Features\n",
        "y = diabetes.label # Target variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7qQHLj3kXIr"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E-jSDs3kaW-"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "diabetes_clf = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "diabetes_clf = clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred = diabetes_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01KT3ZU8lWTZ"
      },
      "source": [
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXNuh1hblagP"
      },
      "source": [
        "import pydotplus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ0MNk2emEVa"
      },
      "source": [
        "!pip install six"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zta9acN1lkYE"
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(better_diabetes_clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True,feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('diabetes.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D39pm18BlXn7"
      },
      "source": [
        "**Can we improve the accuracy?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wra5t0PmvK5"
      },
      "source": [
        "# Create Decision Tree classifer object\n",
        "better_diabetes_clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "better_diabetes_clf = better_diabetes_clf.fit(X_train,y_train)\n",
        "\n",
        "#Predict the response for test dataset\n",
        "y_pred_better = better_diabetes_clf.predict(X_test)\n",
        "\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_better))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9dwbInjnHzx"
      },
      "source": [
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "dot_data = StringIO()\n",
        "export_graphviz(better_diabetes_clf, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True, feature_names = feature_cols,class_names=['0','1'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('bettter_diabetes.png')\n",
        "Image(graph.create_png())\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}