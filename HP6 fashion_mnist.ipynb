{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashion mnist.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUpGqFGJQTVtja++BcreiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/HP6%20fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hev4s-gpA4Eo"
      },
      "source": [
        "# **Fashion-MNIST**\n",
        "\n",
        "60,000 training images of clothing<br>\n",
        "10,000 test images of clothing<br>\n",
        "The images are 28x28 pixels<br>\n",
        "There are 10 classes:<bt>\n",
        "> (\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtG6OJL8Dltz"
      },
      "source": [
        "# **Clone the repo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWpejQ074CEd"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfDPSOSR4yQw"
      },
      "source": [
        "Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset to benchmark machine learning algorithms, as it shares the same image size and the structure of training and testing splits.<br><br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKuNwSUJ4ZXK"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(\"fashion-mnist-sprite.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iK3gZsPSFSCP"
      },
      "source": [
        "# **Set the runtime to GPU**\n",
        "\n",
        "Runtime> Change Runtime Type > Python 3 > GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UjYSxjbDtPD"
      },
      "source": [
        "# **Load the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq-EPIuF_zgD"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import cv2\n",
        "from imutils import build_montages\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "#Adding Callback for early stopping\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N0lyiOv1Bhi"
      },
      "source": [
        "# **Load the Fashion MNIST Data Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOc5X6LW_7CF"
      },
      "source": [
        "#Loading Data\n",
        "(X_train,y_train),(X_test,y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_qeK2w1IQe"
      },
      "source": [
        "print(X_train.size)\n",
        "print(y_train.size)\n",
        "print(X_test.size)\n",
        "print(y_test.size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL-JAq_75U6b"
      },
      "source": [
        "The classes: <br>\n",
        "The ten fashion class labels include:<br>\n",
        "\n",
        "T-shirt/top<br>\n",
        "Trouser/pants<br>\n",
        "Pullover shirt<br>\n",
        "Dress<br>\n",
        "Coat<br>\n",
        "Sandal<br>\n",
        "Shirt<br>\n",
        "Sneaker<br>\n",
        "Bag<br>\n",
        "Ankle boot<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWppSSwC5u1o"
      },
      "source": [
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX_O5rnHD7D3"
      },
      "source": [
        "# **Examine the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahWnCubb257X"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  \n",
        "plt.imshow(X_train[1000], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ6Wtrkz3P2t"
      },
      "source": [
        "plt.imshow(X_test[530], cmap='Greys')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evWi5a8uD_YP"
      },
      "source": [
        "# **Define some of the hyperparameters**<br>\n",
        "<br>\n",
        "In the code below change the '?' to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FGhOs7NAAcC"
      },
      "source": [
        "#defining Parameters\n",
        "num_classes = 10\n",
        "batch_size = ???\n",
        "epoch = ?\n",
        "img_rows, img_cols = 28,28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkAnT5E0EG4A"
      },
      "source": [
        "# **Reshape the images for the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JFftXz7AD9Y"
      },
      "source": [
        "#Deal with format issues between different backends. Some put the no. of channels in the image before the width and height.\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    X_train=X_train.reshape(X_train.shape[0],1,img_rows,img_cols)\n",
        "    X_test =X_test.reshape(X_test.shape[0],1,img_rows,img_cols)\n",
        "    input_shape=(1,img_rows,img_cols)\n",
        "else:\n",
        "    X_train=X_train.reshape(X_train.shape[0],img_rows,img_cols,1)\n",
        "    X_test =X_test.reshape(X_test.shape[0],img_rows,img_cols,1)\n",
        "    input_shape=(img_rows,img_cols,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi1aRBivEMBE"
      },
      "source": [
        "# **Normalize the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kT-ecK-AHUl"
      },
      "source": [
        "#Convert and  scale the test and training data. Bring the scale from 0-255 to 0-1.\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VorNyr6dEPrD"
      },
      "source": [
        "# **Convert data from categorical to numerical**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC9o-UqNAKUr"
      },
      "source": [
        "#Convert class vectors to binary class matrices using One-hot encoding\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes=num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes=num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkcXUMn-EXSw"
      },
      "source": [
        "Define the model<br>\n",
        "kernel sizes, activation functions, pool size, dropout rate, layer size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z75f0zKpANV6"
      },
      "source": [
        "#Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(??,kernel_size=(?,?),activation='??',input_shape=input_shape))\n",
        "model.add(Conv2D(??,kernel_size=(?,?),activation='??'))\n",
        "model.add(MaxPooling2D(pool_size=(?,?)))  \n",
        "#Should more layers be added here?\n",
        "model.add(Flatten())\n",
        "model.add(Dense(???,activation='??'))\n",
        "model.add(Dropout(??))\n",
        "model.add(Dense(num_classes,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wi-vU64EpWL"
      },
      "source": [
        "# **Set up early stopping, if necessary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV7l3XSTAQ9o"
      },
      "source": [
        "my_callback=[EarlyStopping(monitor='val_acc',patience=5,mode=max)]\n",
        "\n",
        "#define compile to minimize categorical loss\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy', \n",
        "    optimizer='adam', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl4eZYosEuNe"
      },
      "source": [
        "# **Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LVXFyXoAUeN"
      },
      "source": [
        "#Train the model and test/validate the mode with the test data after each cycle(epoch) through the training data\n",
        "#Return history of loss and accuracy for each epoch\n",
        "hist= model.fit(X_train,y_train,\n",
        "               batch_size=batch_size,\n",
        "               epochs=epoch,verbose=1,callbacks=my_callback,              \n",
        "               validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MZpWKcDEy5A"
      },
      "source": [
        "# **Plot the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf1ZljFiAmKi"
      },
      "source": [
        "#score = model.evaluate(X_test,y_test,verbose=0)\n",
        "#print('Test loss: ', score[0])\n",
        "#print('Test accuracy', score[1])\n",
        "\n",
        "#hist.history.keys()\n",
        "\n",
        "epoch_list = list(range(1,len(hist.history['accuracy'])+1))  #Values for x axis[1,2,3,4...# of epochs]\n",
        "plt.plot(epoch_list, hist.history['accuracy'],epoch_list,hist.history['val_accuracy'])\n",
        "plt.legend(('Training accuracy','Validation Accuracy'))\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AtuNGoJE3iB"
      },
      "source": [
        "# **Create a montage of the images and labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTC9VTPr8ZHv"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "# initialize our list of output images\n",
        "images = []\n",
        "# randomly select a few testing fashion items\n",
        "for i in np.random.choice(np.arange(0, len(y_test)), size=(16,)):\n",
        "\t# classify the clothing\n",
        "\tprobs = model.predict(X_test[np.newaxis, i])\n",
        "\tprediction = probs.argmax(axis=1)\n",
        "\tlabel = labelNames[prediction[0]]\n",
        " \n",
        "\t# extract the image from the testData if using \"channels_first\"\n",
        "\t# ordering\n",
        "\tif K.image_data_format() == \"channels_first\":\n",
        "\t\timage = (X_test[i][0] * 255).astype(\"uint8\")\n",
        " \n",
        "\t# otherwise we are using \"channels_last\" ordering\n",
        "\telse:\n",
        "\t\timage = (X_test[i] * 255).astype(\"uint8\")\n",
        "  \t# initialize the text label color as green (correct)\n",
        "\tcolor = (0, 255, 0)\n",
        "\t# otherwise, the class label prediction is incorrect\n",
        "\tif prediction[0] != np.argmax(y_test[i]):\n",
        "\t\tcolor = (0, 0, 255)\n",
        " \n",
        "\t# merge the channels into one image and resize the image from\n",
        "\t# 28x28 to 96x96 so we can better see it and then draw the\n",
        "\t# predicted label on the image\n",
        "\timage = cv2.merge([image] * 3)\n",
        "\timage = cv2.resize(image, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
        "\tcv2.putText(image, label, (5, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.75,color, 2)\n",
        "\t# add the image to our list of output images\n",
        "\timages.append(image)\n",
        "# construct the montage for the images\n",
        "montage = build_montages(images, (96, 96), (4, 4))[0]\n",
        "# show the output montage\n",
        "cv2_imshow(montage)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaDOYWsBCcVr",
        "cellView": "form"
      },
      "source": [
        "#@title \n",
        "#defining Parameters\n",
        "num_classes = 10\n",
        "batch_size = 128\n",
        "epoch = 8\n",
        "img_rows, img_cols = 28,28"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQjUN7mkBPpI",
        "cellView": "form"
      },
      "source": [
        "#@title \n",
        "#Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))  \n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkENY6HtC8yd",
        "cellView": "form"
      },
      "source": [
        "#@title \n",
        "https://www.kaggle.com/overload10/keras-conv2d-sample-using-fashion-mnist"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}