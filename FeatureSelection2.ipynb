{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureSelection2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/FeatureSelection2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTLphyOw0wpZ"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlFd8CWKzRBO"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import figure\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.linear_model import LassoCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NVdjjRJ-q6q"
      },
      "source": [
        "# **Get and prepare the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC8hmMo6-4rf"
      },
      "source": [
        "This notebook uses a mushroom data set. <br>\n",
        "It has 8124 rows and 23 categorical columns<br>\n",
        "\n",
        "p = poisonous<br>\n",
        "e = edible\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ONl-APzeRD"
      },
      "source": [
        "df = pd.read_csv('datasets_478_974_mushrooms.csv')\n",
        "pd.options.display.max_columns = None\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pROWVoXd1Isi"
      },
      "source": [
        "percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "missing_values = pd.DataFrame({'percent_missing': percent_missing})\n",
        "missing_values.sort_values(by ='percent_missing' , ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQbun-ti1ORO"
      },
      "source": [
        "sns.set(style=\"ticks\")\n",
        "f = sns.countplot(x=\"class\", data=df, palette=\"bwr\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTuw3WT91SyP"
      },
      "source": [
        "df['class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzkEFwnU1Ued"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzUqF2Bh1vR6"
      },
      "source": [
        "X = df.drop(['class'], axis = 1)\n",
        "Y = df['class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tpkn1wYA8fn"
      },
      "source": [
        "**Convert data from categorical data to one-hot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNZAYBtE1xkn"
      },
      "source": [
        "X = pd.get_dummies(X, prefix_sep='_')\n",
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-jIB9qABKTj"
      },
      "source": [
        "Changing to one-hot means many more columns. <br>\n",
        "From 14 to 118 columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bLi8GYRBEZN"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ri6RGnBY8_"
      },
      "source": [
        "Change the classes from <br>\n",
        "poisonous to 0 <br>\n",
        "edible to 1<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMNYOwbt14_n"
      },
      "source": [
        "Y = LabelEncoder().fit_transform(Y)\n",
        "#np.set_printoptions(threshold=np.inf)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQEyyrz2B_nQ"
      },
      "source": [
        "Standarize the data<br>\n",
        "Split the data into training and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjHzf7Op18Vj"
      },
      "source": [
        "X2 = StandardScaler().fit_transform(X)\n",
        "\n",
        "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X2, Y, test_size = 0.30, random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLquqe32CSTe"
      },
      "source": [
        "# **Create and train a logistic regression model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9glUpK21-7J"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedmodel = LogisticRegression().fit(X_Train,Y_Train)\n",
        "print(\"time = \", time.process_time() - start)\n",
        "predictions =trainedmodel.predict(X_Test)\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(Y_Test,predictions))\n",
        "print(classification_report(Y_Test,predictions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQAGlhn7Cn2k"
      },
      "source": [
        "# **Create and train a support vector model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb3PfFmj2BbZ"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedsvm = svm.LinearSVC().fit(X_Train, Y_Train)\n",
        "print(\"time = \", time.process_time() - start)\n",
        "predictionsvm = trainedsvm.predict(X_Test)\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(Y_Test,predictionsvm))\n",
        "print(classification_report(Y_Test,predictionsvm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWJmKVEMFH5K"
      },
      "source": [
        "# **Create and train a decision tree model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbQpJH6UUEYY"
      },
      "source": [
        "Decision Trees models which are based on ensembles (eg. Extra Trees and Random Forest) can be used to rank the importance of the different features. Knowing which features our model is giving most importance can be of vital importance to understand how our model is making itâ€™s predictions (therefore making it more explainable). At the same time, we can get rid of the features which do not bring any benefit to our model (or confuse it to make a wrong decision!)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy0WgQtP2D6F"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedtree = tree.DecisionTreeClassifier().fit(X_Train, Y_Train)\n",
        "print(\"time = \",time.process_time() - start)\n",
        "predictionstree = trainedtree.predict(X_Test)\n",
        "print(\"Confusion Matrix:\\n\",confusion_matrix(Y_Test,predictionstree))\n",
        "print(classification_report(Y_Test,predictionstree))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbhLPE31QVpw"
      },
      "source": [
        "Show the decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YIJFOdm2Gy_"
      },
      "source": [
        "import graphviz\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "data = export_graphviz(trainedtree,out_file=None,feature_names= X.columns,\n",
        "                       class_names=['edible', 'poisonous'],  \n",
        "                       filled=True, rounded=True,  \n",
        "                       max_depth=2,\n",
        "                       special_characters=True)\n",
        "graph = graphviz.Source(data)\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njyQYN2F2NX3"
      },
      "source": [
        "# **Feature importance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUCln3zCQhB_"
      },
      "source": [
        "Train a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9sI6-zw2Nju"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedforest = RandomForestClassifier(n_estimators=700).fit(X_Train,Y_Train)\n",
        "print(\"time= \",time.process_time() - start)\n",
        "predictionforest = trainedforest.predict(X_Test)\n",
        "print(\"Confusion Matrix: \\n\",confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_n-Mh5zUVTH"
      },
      "source": [
        "# Use the trained forest to create **Feature Importance Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1erji4j2Tce"
      },
      "source": [
        "figure(num=None, figsize=(20, 22), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "feat_importances = pd.Series(trainedforest.feature_importances_, index= X.columns[:])\n",
        "feat_importances.nlargest(19).plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_2Ou3ChWNUv"
      },
      "source": [
        "**Using the top 4 most important features, retrain the model.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz2ru9-G2W-l"
      },
      "source": [
        "X_Reduced = X[['odor_n','odor_f', 'gill-size_n','gill-size_b']]\n",
        "X_Reduced = StandardScaler().fit_transform(X_Reduced)\n",
        "X_Train2, X_Test2, Y_Train2, Y_Test2 = train_test_split(X_Reduced, Y, test_size = 0.30, random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kon8T6JxWm_b"
      },
      "source": [
        "**Retrain the Random Forest model with the top most important features**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh0BS3hlW3d2"
      },
      "source": [
        "Reducing the number of features, the model loses .04% in precision. <br>\n",
        "The training time is reduced from 2.2948669890000133 to 1.3669953309999983"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJvw1UMA2Zko"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedforest = RandomForestClassifier(n_estimators=700).fit(X_Train2,Y_Train2)\n",
        "print(\"time = \",time.process_time() - start)\n",
        "predictionforest = trainedforest.predict(X_Test2)\n",
        "print(\"Confusion Matrix: \\n\",confusion_matrix(Y_Test2,predictionforest))\n",
        "print(classification_report(Y_Test2,predictionforest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FqYTqtb2cQj"
      },
      "source": [
        "**Perform Feature Selection by visualizing a trained Decision Tree structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPRlnxjF2cZA"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=700)\n",
        "rfe = RFE(model)\n",
        "start = time.process_time()\n",
        "RFE_X_Train = rfe.fit_transform(X_Train,Y_Train)\n",
        "RFE_X_Test = rfe.transform(X_Test)\n",
        "rfe = rfe.fit(RFE_X_Train,Y_Train)\n",
        "print(time.process_time() - start)\n",
        "print(\"Overall Accuracy using RFE: \", rfe.score(RFE_X_Test,Y_Test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88y1xbjJ2i3L"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=700)\n",
        "rfe = RFE(model)\n",
        "RFE_X_Train = rfe.fit_transform(X_Train,Y_Train)\n",
        "model.fit(RFE_X_Train,Y_Train) \n",
        "print(\"Number of Features: \", rfe.n_features_)\n",
        "print(\"Selected Features: \")\n",
        "colcheck = pd.Series(rfe.support_,index = list(X.columns[:]))\n",
        "colcheck[colcheck == True].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwWgqZae2mza"
      },
      "source": [
        "**SelectFromModel**: Meta-transformer for selecting features based on importance weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5UDdZLA2qS9"
      },
      "source": [
        "model = ExtraTreesClassifier()\n",
        "start = time.process_time()\n",
        "model = model.fit(X_Train,Y_Train)\n",
        "model = SelectFromModel(model, prefit=True)\n",
        "print(time.process_time() - start)\n",
        "Selected_X = model.transform(X_Train)\n",
        "Selected_X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JD9dZ2t4JWw"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedforest = RandomForestClassifier(n_estimators=700).fit(Selected_X, Y_Train)\n",
        "print(time.process_time() - start)\n",
        "Selected_X_Test = model.transform(X_Test)\n",
        "predictionforest = trainedforest.predict(Selected_X_Test)\n",
        "print(confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yOiXa2W4N_g"
      },
      "source": [
        "# https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html\n",
        "importances = trainedforest.feature_importances_\n",
        "std = np.std([tree.feature_importances_ for tree in trainedforest.estimators_],\n",
        "             axis=0)\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(Selected_X.shape[1]):\n",
        "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
        "\n",
        "# Plot the feature importances of the forest\n",
        "plt.figure()\n",
        "plt.title(\"Feature importances\")\n",
        "plt.bar(range(Selected_X.shape[1]), importances[indices],\n",
        "       color=\"r\", yerr=std[indices], align=\"center\")\n",
        "plt.xticks(range(Selected_X.shape[1]), indices)\n",
        "plt.xlim([-1, Selected_X.shape[1]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueWcuxbg4RDR"
      },
      "source": [
        "# **Correlation matrix analysis**\n",
        "A correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables.\n",
        "<br><br>\n",
        "Most correlation matrixes use Pearsonâ€™s Product-Moment Correlation (r). It is also common to use Spearmanâ€™s Correlation and Kendallâ€™s Tau-b."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jjd9zMY4UP2"
      },
      "source": [
        "Numeric_df = pd.DataFrame(X)\n",
        "Numeric_df['Y'] = Y\n",
        "Numeric_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-264YQG84W4j"
      },
      "source": [
        "figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "corr= Numeric_df.corr()\n",
        "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVGdv5P4rKO0"
      },
      "source": [
        "Decide your correlation threshold and select only those features with correlations above the threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JDz-f43xV1Q"
      },
      "source": [
        "# Selecting only correlated features\n",
        "corr_y = abs(corr[\"Y\"])\n",
        "highest_corr = corr_y[corr_y >0.5]\n",
        "highest_corr.sort_values(ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFsCAWHN4Zon"
      },
      "source": [
        "X_Reduced2 = X[['bruises_f' , 'bruises_t' , 'gill-color_b' , 'gill-size_b' , \n",
        "                'gill-size_n' , 'ring-type_p' , 'stalk-surface-below-ring_k' , \n",
        "                'stalk-surface-above-ring_k' , \n",
        "                'odor_f', 'odor_n']]\n",
        "X_Reduced2 = StandardScaler().fit_transform(X_Reduced2)\n",
        "X_Train3, X_Test3, Y_Train3, Y_Test3 = train_test_split(X_Reduced2, Y, test_size = 0.30, random_state = 101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUPu0ZUG4cfe"
      },
      "source": [
        "start = time.process_time()\n",
        "trainedsvm = svm.LinearSVC().fit(X_Train3, Y_Train3)\n",
        "print(\"time = \",time.process_time() - start)\n",
        "predictionsvm = trainedsvm.predict(X_Test3)\n",
        "print(\"Confusion Matrix:\",confusion_matrix(Y_Test3,predictionsvm))\n",
        "print(classification_report(Y_Test3,predictionsvm))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUgmtXjn-FPj"
      },
      "source": [
        "**Univariate Feature Selection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Cux37n3-JAN"
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "Scaled_X = min_max_scaler.fit_transform(X2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDAtRODx-Mox"
      },
      "source": [
        "X_new = SelectKBest(chi2, k=2).fit_transform(Scaled_X, Y)\n",
        "X_Train3, X_Test3, Y_Train3, Y_Test3 = train_test_split(X_new, Y, test_size = 0.30, random_state = 101)\n",
        "start = time.process_time()\n",
        "trainedforest = RandomForestClassifier(n_estimators=700).fit(X_Train3,Y_Train3)\n",
        "print(time.process_time() - start)\n",
        "predictionforest = trainedforest.predict(X_Test3)\n",
        "print(confusion_matrix(Y_Test3,predictionforest))\n",
        "print(classification_report(Y_Test3,predictionforest))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kndv_k24-Ofa"
      },
      "source": [
        "# **Lasso Regression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPcYgfQc-Rum"
      },
      "source": [
        "regr = LassoCV(cv=5, random_state=101)\n",
        "regr.fit(X_Train,Y_Train)\n",
        "print(\"LassoCV Best Alpha Scored: \", regr.alpha_)\n",
        "print(\"LassoCV Model Accuracy: \", regr.score(X_Test, Y_Test))\n",
        "model_coef = pd.Series(regr.coef_, index = list(X.columns[:-1]))\n",
        "print(\"Variables Eliminated: \", str(sum(model_coef == 0)))\n",
        "print(\"Variables Kept: \", str(sum(model_coef != 0))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeK2liia-UOR"
      },
      "source": [
        "figure(num=None, figsize=(12, 10), dpi=80, facecolor='w', edgecolor='k')\n",
        "\n",
        "top_coef = model_coef.sort_values()\n",
        "top_coef[top_coef != 0].plot(kind = \"barh\")\n",
        "plt.title(\"Most Important Features Identified using Lasso (!0)\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}