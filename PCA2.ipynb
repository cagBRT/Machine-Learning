{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyMS7vQTNFStUCy17wP79ADK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/PCA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwYWelwClZ38"
      },
      "source": [
        "## Dimensionality reduction,\n",
        "\n",
        "an unsupervised machine learning method is used to reduce the number of feature variables for each data sample selecting set of principal features. <br>\n",
        "\n",
        "Principal Component Analysis (PCA) is one of the popular algorithms for dimensionality reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKgjp9cZjJ0J"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTkMpsbDloHG"
      },
      "source": [
        "This example will use sklearn.decomposition.PCA module to find best 5 Principal components from Pima Indians Diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUsl7AxkVgS"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas import read_csv\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYeJB3n3QRK7"
      },
      "source": [
        "The question, given certain features, can we predict who will get diabetes?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gYe4LEmkYZo"
      },
      "source": [
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age','class']\n",
        "dataframe = read_csv('pima_indians_diabetes.csv', names = names, skiprows=1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLlk512Jkn3J"
      },
      "source": [
        "dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B87smPjWXfY5"
      },
      "source": [
        "scatter_matrix(dataframe, alpha=0.2, figsize=(12, 12), diagonal='kde')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzRxtMM1kkT6"
      },
      "source": [
        "array = dataframe.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "print(\"Y has shape: \",Y.shape)\n",
        "print(\"X has shape: \",X.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH6isWwfsbLm"
      },
      "source": [
        "## Examine the variance explained by each principal component\n",
        "\n",
        "We can clearly see that the first  principal component explains over 88% of the variation in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsOephHWh9uv"
      },
      "source": [
        "pca = PCA(n_components = 5)\n",
        "fit = pca.fit(X)\n",
        "print((\"Explained Variance: %s\") % (fit.explained_variance_ratio_))\n",
        "print(\"\\n\")\n",
        "#print(fit.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI-BxGLySCqc"
      },
      "source": [
        "pca.explained_variance_ratio_.cumsum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_D3Jvavrhag"
      },
      "source": [
        "## Scree Test\n",
        "\n",
        "This test is largely visual in that you plot your component number on the horizontal access, and your eigenvalues on the vertical axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC2qIOaNriJr"
      },
      "source": [
        "df = pd.DataFrame({'var':pca.explained_variance_ratio_,'PC':['PC1','PC2','PC3','PC4','PC5']})\n",
        "plt.plot('PC',\"var\",  data=df, color=\"c\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPwoUKlxt-m7"
      },
      "source": [
        "## Use Seaborns Implot\n",
        "Now we can use the top two principal components and make scatter plot. We will use Seaborn’s lmplot to make the PCA plot using the fit_reg=False option and color clusters with ‘hue’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNubI5E3uv1M"
      },
      "source": [
        "pc = pca.fit_transform(X)\n",
        "pc_df = pd.DataFrame(data = pc ,\n",
        "        columns = ['PC1', 'PC2','PC3','PC4','PC5'])\n",
        "pc_df['Cluster'] = Y\n",
        "pc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSiVLNvJzbsF"
      },
      "source": [
        "We can clearly see the two clusters in our data. The two principal components are able to completely separate the clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoXSMVdYuAE0"
      },
      "source": [
        "sns.lmplot( x=\"PC1\", y=\"Cluster\",\n",
        "  data=pc_df,\n",
        "  fit_reg=False,\n",
        "  hue='Cluster', # color by cluster\n",
        "  legend=True,\n",
        "  scatter_kws={\"s\": 60}) # specify the point size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSLM_e5LUMJA"
      },
      "source": [
        "sns.lmplot( x=\"PC1\", y=\"PC2\",\n",
        "  data=pc_df,\n",
        "  fit_reg=False,\n",
        "  hue='Cluster', # color by cluster\n",
        "  legend=True,\n",
        "  scatter_kws={\"s\": 60}) # specify the point size"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}