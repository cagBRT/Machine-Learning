{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCA2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOMtPbuE1Bw3h5ok2D6Rnh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/PCA2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwYWelwClZ38",
        "colab_type": "text"
      },
      "source": [
        "Dimensionality reduction, an unsupervised machine learning method is used to reduce the number of feature variables for each data sample selecting set of principal features. Principal Component Analysis (PCA) is one of the popular algorithms for dimensionality reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKgjp9cZjJ0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Machine-Learning.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTkMpsbDloHG",
        "colab_type": "text"
      },
      "source": [
        "This example will use sklearn.decomposition.PCA module to find best 5 Principal components from Pima Indians Diabetes dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOUsl7AxkVgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pandas import read_csv\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gYe4LEmkYZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age','class']\n",
        "dataframe = read_csv('pima_indians_diabetes.csv', names = names, skiprows=1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLlk512Jkn3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B87smPjWXfY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scatter_matrix(dataframe, alpha=0.2, figsize=(12, 12), diagonal='kde')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzRxtMM1kkT6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array = dataframe.values\n",
        "X = array[:,0:8] #started with 1 to remove header row\n",
        "Y = array[:,8]\n",
        "Y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH6isWwfsbLm",
        "colab_type": "text"
      },
      "source": [
        "examine the variance explained by each principal component. We can clearly see that the first  principal component explains over 88% of the variation in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsOephHWh9uv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components = 5)\n",
        "fit = pca.fit(X)\n",
        "print((\"Explained Variance: %s\") % (fit.explained_variance_ratio_))\n",
        "print(\"\\n\")\n",
        "print(fit.components_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_D3Jvavrhag",
        "colab_type": "text"
      },
      "source": [
        "Scree Test\n",
        "\n",
        "This test is largely visual in that you plot your component number on the horizontal access, and your eigenvalues on the vertical axis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC2qIOaNriJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame({'var':pca.explained_variance_ratio_,'PC':['PC1','PC2','PC3','PC4','PC5']})\n",
        "plt.plot('PC',\"var\",  data=df, color=\"c\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPwoUKlxt-m7",
        "colab_type": "text"
      },
      "source": [
        "Now we can use the top two principal components and make scatter plot. We will use Seaborn’s lmplot to make the PCA plot using the fit_reg=False option and color clusters with ‘hue’."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNubI5E3uv1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pc = pca.fit_transform(X)\n",
        "pc_df = pd.DataFrame(data = pc , \n",
        "        columns = ['PC1', 'PC2','PC3','PC4','PC5'])\n",
        "pc_df['Cluster'] = Y\n",
        "pc_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSiVLNvJzbsF",
        "colab_type": "text"
      },
      "source": [
        "We can clearly see the two clusters in our data. The two principal components are able to completely separate the clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoXSMVdYuAE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.lmplot( x=\"PC1\", y=\"PC2\",\n",
        "  data=pc_df, \n",
        "  fit_reg=False, \n",
        "  hue='Cluster', # color by cluster\n",
        "  legend=True,\n",
        "  scatter_kws={\"s\": 60}) # specify the point size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLge3NN3gbTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=pc_df.iloc[:,1]\n",
        "y=pc_df.iloc[:,2]\n",
        "z=pc_df.iloc[:,3]\n",
        "\n",
        "fig = plt.figure(figsize=(8, 6))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "ax.scatter(x, y, z, s=60, alpha=0.6, edgecolors='w', c=pc_df.iloc[:,5])\n",
        "\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "ax.set_zlabel('PC3')\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}