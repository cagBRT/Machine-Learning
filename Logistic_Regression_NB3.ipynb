{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression NB3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP5w0M5FYzhvTcTuPj3oej/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Machine-Learning/blob/master/Logistic_Regression_NB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8Q7ulDCjBH7"
      },
      "source": [
        "# **Logistic Regression on a small sample of the MNIST dataset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75zsfm3LNFDz"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHvxEXANM_Ka"
      },
      "source": [
        "**Get the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7tQYLGKhNfN"
      },
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F6rnmAjhIOz"
      },
      "source": [
        "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
        "print(\"Image Data Shape = \" , digits.data.shape)\n",
        "# Print to show there are 1797 labels (integers from 0â€“9)\n",
        "print(\"Label Data Shape\", digits.target.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfdDlsS_hbaI"
      },
      "source": [
        "plt.figure(figsize=(20,4))\n",
        "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
        " plt.subplot(1, 5, index + 1)\n",
        " plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
        " plt.title('Training: %i\\n' % label, fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roMUJYFrNdC1"
      },
      "source": [
        "**Training - Test Data split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq8ggKVNhRNQ"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to6XljqBNTwX"
      },
      "source": [
        "**Create the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDqBMtRSicmx"
      },
      "source": [
        "# all parameters not specified are set to their defaults\n",
        "logisticRegr = LogisticRegression()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC0TQWILZL7E"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkzp--q3NXU-"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4uiW-8Iiel0"
      },
      "source": [
        "logisticRegr.fit(x_train, y_train,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq8b27fZNim7"
      },
      "source": [
        "**Make predictions with the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjy0I0YrikfO"
      },
      "source": [
        "# Returns a NumPy Array\n",
        "# Predict for One Observation (image)\n",
        "logisticRegr.predict(x_test[0].reshape(1,-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTgZiuG5Nr0a"
      },
      "source": [
        "**Make multiple predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfYstMIQinHU"
      },
      "source": [
        "logisticRegr.predict(x_test[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSSQoK7yNzr3"
      },
      "source": [
        "**Predict with the test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-E6B5zYipc3"
      },
      "source": [
        "predictions = logisticRegr.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-RGf1h3N5dR"
      },
      "source": [
        "**What is the model accuracy?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhQ1O4EvisE2"
      },
      "source": [
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(x_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEqV-CxiOB-x"
      },
      "source": [
        "**The confusion matrix for the digits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFU9lAR1iwxY"
      },
      "source": [
        "cm = metrics.confusion_matrix(y_test, predictions)\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWdEtrKJiz39"
      },
      "source": [
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bse3UGLxYaNc"
      },
      "source": [
        "List the instances where ground truth and the prediction differ<br>\n",
        "(The model got it wrong)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fHeeIDKagRn"
      },
      "source": [
        "index = 0\n",
        "misclassifiedIndexes = []\n",
        "misclassifiedIndexes2 = []\n",
        "for label, predict in zip(y_test, predictions):\n",
        " if label != predict: \n",
        "  print(label, predict)\n",
        "  misclassifiedIndexes.append(label)\n",
        "  misclassifiedIndexes2.append(predict)\n",
        "  index +=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4QmB_TCa4I-"
      },
      "source": [
        "plt.figure(figsize=(20,4))\n",
        "for plotIndex, badIndex in enumerate(misclassifiedIndexes[0:5]):\n",
        " plt.subplot(1, 5, plotIndex + 1)\n",
        " plt.imshow(np.reshape(x_test[badIndex], (8,8)), cmap=plt.cm.gray)\n",
        " plt.title(\"Predicted {}, Actual {}\".format(misclassifiedIndexes2[plotIndex], misclassifiedIndexes[plotIndex]), fontsize = 15)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}